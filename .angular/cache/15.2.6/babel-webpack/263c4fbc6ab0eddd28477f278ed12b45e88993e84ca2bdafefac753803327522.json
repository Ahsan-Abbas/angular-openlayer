{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/ahsanabbas/Angular/angular-openlayers/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport QuickLRU from 'quick-lru';\nimport { BaseSource } from './basesource.js';\nimport { AbortError, AggregateError, wait, zip } from '../utils.js';\nclass Block {\n  /**\n   *\n   * @param {number} offset\n   * @param {number} length\n   * @param {ArrayBuffer} [data]\n   */\n  constructor(offset, length, data = null) {\n    this.offset = offset;\n    this.length = length;\n    this.data = data;\n  }\n\n  /**\n   * @returns {number} the top byte border\n   */\n  get top() {\n    return this.offset + this.length;\n  }\n}\nclass BlockGroup {\n  /**\n   *\n   * @param {number} offset\n   * @param {number} length\n   * @param {number[]} blockIds\n   */\n  constructor(offset, length, blockIds) {\n    this.offset = offset;\n    this.length = length;\n    this.blockIds = blockIds;\n  }\n}\nexport class BlockedSource extends BaseSource {\n  /**\n   *\n   * @param {BaseSource} source The underlying source that shall be blocked and cached\n   * @param {object} options\n   * @param {number} [options.blockSize]\n   * @param {number} [options.cacheSize]\n   */\n  constructor(source, {\n    blockSize = 65536,\n    cacheSize = 100\n  } = {}) {\n    super();\n    this.source = source;\n    this.blockSize = blockSize;\n    this.blockCache = new QuickLRU({\n      maxSize: cacheSize,\n      onEviction: (blockId, block) => {\n        this.evictedBlocks.set(blockId, block);\n      }\n    });\n\n    /** @type {Map<number, Block>} */\n    this.evictedBlocks = new Map();\n\n    // mapping blockId -> Block instance\n    this.blockRequests = new Map();\n\n    // set of blockIds missing for the current requests\n    this.blockIdsToFetch = new Set();\n    this.abortedBlockIds = new Set();\n  }\n  get fileSize() {\n    return this.source.fileSize;\n  }\n\n  /**\n   *\n   * @param {import(\"./basesource\").Slice[]} slices\n   */\n  fetch(slices, signal) {\n    var _this = this;\n    return _asyncToGenerator(function* () {\n      const blockRequests = [];\n      const missingBlockIds = [];\n      const allBlockIds = [];\n      _this.evictedBlocks.clear();\n      for (const {\n        offset,\n        length\n      } of slices) {\n        let top = offset + length;\n        const {\n          fileSize\n        } = _this;\n        if (fileSize !== null) {\n          top = Math.min(top, fileSize);\n        }\n        const firstBlockOffset = Math.floor(offset / _this.blockSize) * _this.blockSize;\n        for (let current = firstBlockOffset; current < top; current += _this.blockSize) {\n          const blockId = Math.floor(current / _this.blockSize);\n          if (!_this.blockCache.has(blockId) && !_this.blockRequests.has(blockId)) {\n            _this.blockIdsToFetch.add(blockId);\n            missingBlockIds.push(blockId);\n          }\n          if (_this.blockRequests.has(blockId)) {\n            blockRequests.push(_this.blockRequests.get(blockId));\n          }\n          allBlockIds.push(blockId);\n        }\n      }\n\n      // allow additional block requests to accumulate\n      yield wait();\n      _this.fetchBlocks(signal);\n\n      // Gather all of the new requests that this fetch call is contributing to `fetch`.\n      const missingRequests = [];\n      for (const blockId of missingBlockIds) {\n        // The requested missing block could already be in the cache\n        // instead of having its request still be outstanding.\n        if (_this.blockRequests.has(blockId)) {\n          missingRequests.push(_this.blockRequests.get(blockId));\n        }\n      }\n\n      // Actually await all pending requests that are needed for this `fetch`.\n      yield Promise.allSettled(blockRequests);\n      yield Promise.allSettled(missingRequests);\n\n      // Perform retries if a block was interrupted by a previous signal\n      const abortedBlockRequests = [];\n      const abortedBlockIds = allBlockIds.filter(id => _this.abortedBlockIds.has(id) || !_this.blockCache.has(id));\n      abortedBlockIds.forEach(id => _this.blockIdsToFetch.add(id));\n      // start the retry of some blocks if required\n      if (abortedBlockIds.length > 0 && signal && !signal.aborted) {\n        _this.fetchBlocks(null);\n        for (const blockId of abortedBlockIds) {\n          const block = _this.blockRequests.get(blockId);\n          if (!block) {\n            throw new Error(`Block ${blockId} is not in the block requests`);\n          }\n          abortedBlockRequests.push(block);\n        }\n        yield Promise.allSettled(abortedBlockRequests);\n      }\n\n      // throw an  abort error\n      if (signal && signal.aborted) {\n        throw new AbortError('Request was aborted');\n      }\n      const blocks = allBlockIds.map(id => _this.blockCache.get(id) || _this.evictedBlocks.get(id));\n      const failedBlocks = blocks.filter(i => !i);\n      if (failedBlocks.length) {\n        throw new AggregateError(failedBlocks, 'Request failed');\n      }\n\n      // create a final Map, with all required blocks for this request to satisfy\n      const requiredBlocks = new Map(zip(allBlockIds, blocks));\n\n      // TODO: satisfy each slice\n      return _this.readSliceData(slices, requiredBlocks);\n    })();\n  }\n\n  /**\n   *\n   * @param {AbortSignal} signal\n   */\n  fetchBlocks(signal) {\n    var _this2 = this;\n    // check if we still need to\n    if (this.blockIdsToFetch.size > 0) {\n      const groups = this.groupBlocks(this.blockIdsToFetch);\n\n      // start requesting slices of data\n      const groupRequests = this.source.fetch(groups, signal);\n      for (let groupIndex = 0; groupIndex < groups.length; ++groupIndex) {\n        const group = groups[groupIndex];\n        for (const blockId of group.blockIds) {\n          // make an async IIFE for each block\n          this.blockRequests.set(blockId, _asyncToGenerator(function* () {\n            try {\n              const response = (yield groupRequests)[groupIndex];\n              const blockOffset = blockId * _this2.blockSize;\n              const o = blockOffset - response.offset;\n              const t = Math.min(o + _this2.blockSize, response.data.byteLength);\n              const data = response.data.slice(o, t);\n              const block = new Block(blockOffset, data.byteLength, data, blockId);\n              _this2.blockCache.set(blockId, block);\n              _this2.abortedBlockIds.delete(blockId);\n            } catch (err) {\n              if (err.name === 'AbortError') {\n                // store the signal here, we need it to determine later if an\n                // error was caused by this signal\n                err.signal = signal;\n                _this2.blockCache.delete(blockId);\n                _this2.abortedBlockIds.add(blockId);\n              } else {\n                throw err;\n              }\n            } finally {\n              _this2.blockRequests.delete(blockId);\n            }\n          })());\n        }\n      }\n      this.blockIdsToFetch.clear();\n    }\n  }\n\n  /**\n   *\n   * @param {Set} blockIds\n   * @returns {BlockGroup[]}\n   */\n  groupBlocks(blockIds) {\n    const sortedBlockIds = Array.from(blockIds).sort((a, b) => a - b);\n    if (sortedBlockIds.length === 0) {\n      return [];\n    }\n    let current = [];\n    let lastBlockId = null;\n    const groups = [];\n    for (const blockId of sortedBlockIds) {\n      if (lastBlockId === null || lastBlockId + 1 === blockId) {\n        current.push(blockId);\n        lastBlockId = blockId;\n      } else {\n        groups.push(new BlockGroup(current[0] * this.blockSize, current.length * this.blockSize, current));\n        current = [blockId];\n        lastBlockId = blockId;\n      }\n    }\n    groups.push(new BlockGroup(current[0] * this.blockSize, current.length * this.blockSize, current));\n    return groups;\n  }\n\n  /**\n   *\n   * @param {import(\"./basesource\").Slice[]} slices\n   * @param {Map} blocks\n   */\n  readSliceData(slices, blocks) {\n    return slices.map(slice => {\n      let top = slice.offset + slice.length;\n      if (this.fileSize !== null) {\n        top = Math.min(this.fileSize, top);\n      }\n      const blockIdLow = Math.floor(slice.offset / this.blockSize);\n      const blockIdHigh = Math.floor(top / this.blockSize);\n      const sliceData = new ArrayBuffer(slice.length);\n      const sliceView = new Uint8Array(sliceData);\n      for (let blockId = blockIdLow; blockId <= blockIdHigh; ++blockId) {\n        const block = blocks.get(blockId);\n        const delta = block.offset - slice.offset;\n        const topDelta = block.top - top;\n        let blockInnerOffset = 0;\n        let rangeInnerOffset = 0;\n        let usedBlockLength;\n        if (delta < 0) {\n          blockInnerOffset = -delta;\n        } else if (delta > 0) {\n          rangeInnerOffset = delta;\n        }\n        if (topDelta < 0) {\n          usedBlockLength = block.length - blockInnerOffset;\n        } else {\n          usedBlockLength = top - block.offset - blockInnerOffset;\n        }\n        const blockView = new Uint8Array(block.data, blockInnerOffset, usedBlockLength);\n        sliceView.set(blockView, rangeInnerOffset);\n      }\n      return sliceData;\n    });\n  }\n}","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}